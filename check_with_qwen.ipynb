{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6074359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file: ballerina_grpo_X4.json\n",
      "Output file: ballerina_grpo_X4_inference_results.json\n",
      "Model: didula-wso2/exp_23_emb_grpo_checkpoint_1000_16bit_vllm\n",
      "Generations per problem: 5\n",
      "Test pass threshold: 75.0%\n",
      "\n",
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:104: UserWarning: \n",
      "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
      "You are not authenticated with the Hugging Face Hub in this notebook.\n",
      "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4205114d70f74753ba465e4b0ed44baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c749642e724e82a543f0208300bbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3d62fd55dd4fdc8bf52f072a6d9862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b78e454d2894da7aed4aef79fcbe8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4deabf65a798417c91a2c5fe772b6fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/632 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1cbeace50594dfda2f4f1e906894c81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/613 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1f260b452c4dbca41fbbcfd17a0e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.jinja: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896cda8cd6f2497da8d6eee2c002c46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ba475fa1ed42b99f1ac1373eebac9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b0f7fbee574c42ae34de9025e549a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb96eaf190f427db2a06f3b1f2620b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b0561213714b23b08755548b47ec42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0525bd3decb9406fadba5d7162cbe4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7d18d688494e49816d7e4f351cef21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18ac34049d8b487d9eb3ed84cee475c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Inference script for HuggingFace model on Ballerina problems.\n",
    "Generates 5 completions per problem and evaluates them using test cases.\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import base64\n",
    "import zlib\n",
    "import pickle\n",
    "import subprocess\n",
    "import tempfile\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# Configuration\n",
    "INPUT_FILE = Path(\"ballerina_grpo_X4.json\")\n",
    "OUTPUT_FILE = Path(\"ballerina_grpo_X4_inference_results.json\")\n",
    "MODEL_NAME = \"didula-wso2/exp_23_emb_grpo_checkpoint_1000_16bit_vllm\"\n",
    "NUM_GENERATIONS = 5\n",
    "THRESHOLD = 0.75  # 75% of test cases must pass\n",
    "\n",
    "print(f\"Input file: {INPUT_FILE}\")\n",
    "print(f\"Output file: {OUTPUT_FILE}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Generations per problem: {NUM_GENERATIONS}\")\n",
    "print(f\"Test pass threshold: {THRESHOLD*100}%\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "print(\"\\nLoading model and tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# System prompt for Ballerina code generation (matching generate_corrections.ipynb)\n",
    "SYSTEM_PROMPT = \"\"\"You are a pragmatic Ballerina programmer who enjoys test driven development. Given the following question, write a Ballerina script to complete the task and then write the the unit tests to validate the functionality. Also implement a main function check with a user input.\n",
    "\n",
    "1. Make the code simple and easy to understand.\n",
    "2. Try to limit library usage to the standard library. Be careful with your types, and try to limit yourself to the basic built in types and standard library functions.\n",
    "3. Before you start writing the function you can think through how to solve the problem and perform reasoning in the comments above the function.\n",
    "4. Implement a main function to accept user inputs. Output the outputs of the function.\n",
    "5. Don't define inputs yourself. Do not hardcode inputs. Only use user inputs.\n",
    "6. Then write unit tests for the function you defined. Make sure to write at least 4 assertions to test the function. The tests should be a simple.\n",
    "\n",
    "[Important] Strictly follow the following output format for each response: Make sure to include code inside <CODE> and <TESTS> blocks. Only use Ballerina Programming Language. Never use any other programming languages. Implement proper error handling.\n",
    "\n",
    "# Overview\n",
    "Brief overview about the solution.\n",
    "\n",
    "<CODE>\n",
    "```ballerina\n",
    "// Reasoning goes here\n",
    "// and can be multi-line\n",
    "\n",
    "import ballerina/io;\n",
    "\n",
    "function add(int a, int b) returns int {\n",
    "    return a + b;\n",
    "}\n",
    "\n",
    "public function main() {\n",
    "    string? input_line = io:readln();\n",
    "    if input_line is string {\n",
    "        string[] parts = input_line.split(\" \");\n",
    "        if parts.length() == 2 {\n",
    "            int|error first_num = 'int:fromString(parts[0]);\n",
    "            int|error second_num = 'int:fromString(parts[1]);\n",
    "\n",
    "            if first_num is int && second_num is int {\n",
    "                int result = add(first_num, second_num);\n",
    "                io:println(result.toString());\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "</CODE>\n",
    "\n",
    "<TESTS>\n",
    "```ballerina\n",
    "import ballerina/test;\n",
    "\n",
    "@test:Config { }\n",
    "function testAssertEquals() {\n",
    "    int addResult = add(40, 2);\n",
    "    test:assertEquals(addResult, 42);\n",
    "\n",
    "    addResult = add(0, 0);\n",
    "    test:assertEquals(addResult, 0);\n",
    "\n",
    "    addResult = add(-1, 1);\n",
    "    test:assertEquals(addResult, 0);\n",
    "\n",
    "    addResult = add(-5, -5);\n",
    "    test:assertEquals(addResult, -10);\n",
    "}\n",
    "```\n",
    "</TESTS>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def decode_answer_field(answer_str: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"Decode test cases from answer field: base64 â†’ zlib â†’ pickle â†’ JSON\"\"\"\n",
    "    try:\n",
    "        # Base64 decode\n",
    "        decoded_bytes = base64.b64decode(answer_str.encode(\"utf-8\"))\n",
    "        # Zlib decompress\n",
    "        decompressed = zlib.decompress(decoded_bytes)\n",
    "        # Pickle loads\n",
    "        pickled_data = pickle.loads(decompressed)\n",
    "        # JSON loads\n",
    "        test_cases = json.loads(pickled_data)\n",
    "        return test_cases\n",
    "    except Exception as e:\n",
    "        print(f\"    Error decoding answer field: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def extract_code_from_completion(completion: str) -> Optional[str]:\n",
    "    \"\"\"Extract code block from completion following generate_corrections.ipynb pattern\"\"\"\n",
    "    if '<CODE>' in completion and '</CODE>' in completion:\n",
    "        code_section = completion.split('<CODE>')[1].split('</CODE>')[0]\n",
    "        # Extract from ballerina code block\n",
    "        if '```ballerina' in code_section:\n",
    "            code = code_section.split('```ballerina')[1].split('```')[0].strip()\n",
    "        elif '```' in code_section:\n",
    "            code = code_section.split('```')[1].split('```')[0].strip()\n",
    "        else:\n",
    "            code = code_section.strip()\n",
    "        return code\n",
    "    return None\n",
    "\n",
    "\n",
    "def normalize_output(output: str) -> str:\n",
    "    \"\"\"Normalize output by stripping trailing whitespace from each line and the entire output\"\"\"\n",
    "    lines = output.split('\\n')\n",
    "    normalized_lines = [line.rstrip() for line in lines]\n",
    "    return '\\n'.join(normalized_lines).strip()\n",
    "\n",
    "\n",
    "def run_test_cases(code: str, test_cases: List[Dict[str, str]], threshold: float = 0.75) -> Tuple[bool, int, int, str, Dict]:\n",
    "    \"\"\"Run test cases and check if at least threshold% pass\n",
    "    Returns: (is_valid, passed, total, validation_msg, error_details)\n",
    "    error_details includes: compilation_error, failing_test_case\n",
    "    \"\"\"\n",
    "    if not code:\n",
    "        return False, 0, 0, \"No code extracted\", {}\n",
    "    \n",
    "    # Check for basic Ballerina structure\n",
    "    if 'function main()' not in code and 'public function main()' not in code:\n",
    "        return False, 0, 0, \"Missing main function\", {}\n",
    "    \n",
    "    error_details = {}\n",
    "    \n",
    "    if not test_cases or len(test_cases) == 0:\n",
    "        # No test cases, fall back to compilation check\n",
    "        with tempfile.TemporaryDirectory() as tmpdir:\n",
    "            code_file = Path(tmpdir) / \"main.bal\"\n",
    "            code_file.write_text(code)\n",
    "            \n",
    "            try:\n",
    "                result = subprocess.run(\n",
    "                    [\"bal\", \"build\", \"main.bal\"],\n",
    "                    cwd=tmpdir,\n",
    "                    capture_output=True,\n",
    "                    text=True,\n",
    "                    timeout=30\n",
    "                )\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    return True, 0, 0, \"Code compiles (no test cases)\", {}\n",
    "                else:\n",
    "                    error_details['compilation_error'] = result.stderr\n",
    "                    return False, 0, 0, f\"Compilation error: {result.stderr[:500]}\", error_details\n",
    "            except Exception as e:\n",
    "                error_details['compilation_error'] = str(e)\n",
    "                return False, 0, 0, f\"Validation error: {str(e)}\", error_details\n",
    "    \n",
    "    # First, try to compile the code\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        code_file = Path(tmpdir) / \"main.bal\"\n",
    "        code_file.write_text(code)\n",
    "        \n",
    "        # Check compilation first\n",
    "        compile_result = subprocess.run(\n",
    "            [\"bal\", \"build\", \"main.bal\"],\n",
    "            cwd=tmpdir,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if compile_result.returncode != 0:\n",
    "            error_details['compilation_error'] = compile_result.stderr\n",
    "            return False, 0, len(test_cases), f\"Compilation error: {compile_result.stderr[:500]}\", error_details\n",
    "        \n",
    "        # Code compiles, now run test cases\n",
    "        passed = 0\n",
    "        failed = 0\n",
    "        first_failing_test = None\n",
    "        \n",
    "        for idx, test_case in enumerate(test_cases):\n",
    "            test_input = test_case.get('input', '')\n",
    "            expected_output = test_case.get('output', '')\n",
    "            \n",
    "            # Normalize expected output\n",
    "            expected_output_normalized = normalize_output(expected_output)\n",
    "            \n",
    "            try:\n",
    "                # Write input to temp file\n",
    "                input_file = Path(tmpdir) / f\"input_{idx}.txt\"\n",
    "                input_file.write_text(test_input)\n",
    "                \n",
    "                # Run the code\n",
    "                with open(input_file, 'r') as inp:\n",
    "                    result = subprocess.run(\n",
    "                        [\"bal\", \"run\", \"main.bal\"],\n",
    "                        cwd=tmpdir,\n",
    "                        stdin=inp,\n",
    "                        capture_output=True,\n",
    "                        text=True,\n",
    "                        timeout=10\n",
    "                    )\n",
    "                \n",
    "                if result.returncode != 0:\n",
    "                    failed += 1\n",
    "                    # Capture first failing test with runtime error\n",
    "                    if first_failing_test is None:\n",
    "                        first_failing_test = {\n",
    "                            'input': test_input,\n",
    "                            'expected_output': expected_output,\n",
    "                            'actual_output': result.stderr if result.stderr else result.stdout,\n",
    "                            'error': f\"Runtime error (exit code {result.returncode})\"\n",
    "                        }\n",
    "                    continue\n",
    "                \n",
    "                # Normalize actual output\n",
    "                actual_output_normalized = normalize_output(result.stdout)\n",
    "                \n",
    "                if actual_output_normalized == expected_output_normalized:\n",
    "                    passed += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "                    # Capture first failing test with output mismatch\n",
    "                    if first_failing_test is None:\n",
    "                        first_failing_test = {\n",
    "                            'input': test_input,\n",
    "                            'expected_output': expected_output,\n",
    "                            'actual_output': result.stdout,\n",
    "                            'error': 'Output mismatch'\n",
    "                        }\n",
    "                    \n",
    "            except subprocess.TimeoutExpired:\n",
    "                failed += 1\n",
    "                if first_failing_test is None:\n",
    "                    first_failing_test = {\n",
    "                        'input': test_input,\n",
    "                        'expected_output': expected_output,\n",
    "                        'actual_output': '',\n",
    "                        'error': 'Timeout (code took >10 seconds)'\n",
    "                    }\n",
    "            except Exception as e:\n",
    "                failed += 1\n",
    "                if first_failing_test is None:\n",
    "                    first_failing_test = {\n",
    "                        'input': test_input,\n",
    "                        'expected_output': expected_output,\n",
    "                        'actual_output': '',\n",
    "                        'error': str(e)\n",
    "                    }\n",
    "        \n",
    "        total = len(test_cases)\n",
    "        pass_rate = passed / total if total > 0 else 0\n",
    "        \n",
    "        if pass_rate >= threshold:\n",
    "            return True, passed, total, f\"Passed {passed}/{total} tests ({pass_rate*100:.1f}%)\", {}\n",
    "        else:\n",
    "            if first_failing_test:\n",
    "                error_details['failing_test_case'] = first_failing_test\n",
    "            return False, passed, total, f\"Only passed {passed}/{total} tests ({pass_rate*100:.1f}%), need {threshold*100:.0f}%\", error_details\n",
    "\n",
    "\n",
    "def generate_completion(model, tokenizer, prompt: str, device, max_new_tokens: int = 2048) -> str:\n",
    "    \"\"\"Generate a single completion using the model\"\"\"\n",
    "    # Format prompt with system prompt\n",
    "    full_prompt = f\"\"\"{SYSTEM_PROMPT}\n",
    "\n",
    "Problem:\n",
    "{prompt}\n",
    "\n",
    "Please generate Ballerina code that solves the problem above. Make sure to:\n",
    "1. Read input from stdin (not command line arguments) using io:readln() or similar\n",
    "2. Process the input according to the problem specification\n",
    "3. Output the result to stdout using io:println()\n",
    "4. Handle all edge cases properly\n",
    "5. Use proper error handling\n",
    "\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": full_prompt},\n",
    "    ]\n",
    "    \n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    # Move inputs to device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decode only the new tokens\n",
    "    generated_text = tokenizer.decode(\n",
    "        outputs[0][inputs[\"input_ids\"].shape[-1]:],\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    return generated_text\n",
    "\n",
    "\n",
    "def process_problem(problem: Dict[str, Any], model, tokenizer, device, problem_idx: int) -> Dict[str, Any]:\n",
    "    \"\"\"Process a single problem: generate 5 completions and evaluate each\"\"\"\n",
    "    prompt = problem.get('prompt', '')\n",
    "    answer = problem.get('answer', '')\n",
    "    \n",
    "    # Decode test cases from answer field\n",
    "    test_cases = decode_answer_field(answer)\n",
    "    if test_cases:\n",
    "        print(f\"  ðŸ“‹ {len(test_cases)} test cases decoded\")\n",
    "    else:\n",
    "        print(f\"  âš  No test cases found in answer field\")\n",
    "    \n",
    "    generations = []\n",
    "    \n",
    "    for gen_idx in range(NUM_GENERATIONS):\n",
    "        print(f\"  Generating completion {gen_idx + 1}/{NUM_GENERATIONS}...\")\n",
    "        \n",
    "        try:\n",
    "            # Generate completion\n",
    "            completion = generate_completion(model, tokenizer, prompt, device=device)\n",
    "            \n",
    "            # Extract code\n",
    "            code = extract_code_from_completion(completion)\n",
    "            \n",
    "            if not code:\n",
    "                print(f\"    âš  Could not extract code from completion\")\n",
    "                generations.append({\n",
    "                    'completion': completion,\n",
    "                    'code': None,\n",
    "                    'passed': False,\n",
    "                    'tests_passed': 0,\n",
    "                    'tests_total': len(test_cases),\n",
    "                    'pass_rate': 0.0,\n",
    "                    'validation_msg': 'Could not extract code'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Evaluate test cases\n",
    "            is_valid, passed, total, validation_msg, error_details = run_test_cases(\n",
    "                code, test_cases, threshold=THRESHOLD\n",
    "            )\n",
    "            \n",
    "            pass_rate = passed / total if total > 0 else 0.0\n",
    "            \n",
    "            generations.append({\n",
    "                'completion': completion,\n",
    "                'code': code,\n",
    "                'passed': is_valid,\n",
    "                'tests_passed': passed,\n",
    "                'tests_total': total,\n",
    "                'pass_rate': pass_rate,\n",
    "                'validation_msg': validation_msg,\n",
    "                'error_details': error_details if error_details else None\n",
    "            })\n",
    "            \n",
    "            status = \"âœ“\" if is_valid else \"âœ—\"\n",
    "            print(f\"    {status} {validation_msg}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    âœ— Error generating/evaluating: {e}\")\n",
    "            generations.append({\n",
    "                'completion': None,\n",
    "                'code': None,\n",
    "                'passed': False,\n",
    "                'tests_passed': 0,\n",
    "                'tests_total': len(test_cases),\n",
    "                'pass_rate': 0.0,\n",
    "                'validation_msg': f'Error: {str(e)}',\n",
    "                'error_details': None\n",
    "            })\n",
    "    \n",
    "    # Count passing generations\n",
    "    passing_generations = sum(1 for gen in generations if gen['passed'])\n",
    "    \n",
    "    # Create result entry\n",
    "    result = {\n",
    "        **{k: v for k, v in problem.items() if k not in ['generations', 'passing_generations']},\n",
    "        'generations': generations,\n",
    "        'passing_generations': passing_generations\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load problems\n",
    "    print(f\"\\nLoading problems from {INPUT_FILE}...\")\n",
    "    with open(INPUT_FILE, 'r', encoding='utf-8') as f:\n",
    "        problems = json.load(f)\n",
    "    \n",
    "    print(f\"Loaded {len(problems)} problems\")\n",
    "    print(f\"Processing problems 1-{min(5018, len(problems))}...\")\n",
    "    \n",
    "    # Process problems\n",
    "    results = []\n",
    "    stats = {\n",
    "        'total': 0,\n",
    "        'passing_1': 0,\n",
    "        'passing_2': 0,\n",
    "        'passing_3': 0,\n",
    "        'passing_4': 0,\n",
    "        'passing_5': 0,\n",
    "        'passing_0': 0\n",
    "    }\n",
    "    \n",
    "    for idx, problem in enumerate(problems[:5018]):\n",
    "        problem_num = idx + 1\n",
    "        print(f\"\\n[{problem_num}/5018] Processing problem {idx} (rating: {problem.get('rating', 'unknown')})...\")\n",
    "        \n",
    "        result = process_problem(problem, model, tokenizer, device, idx)\n",
    "        results.append(result)\n",
    "        \n",
    "        # Update stats\n",
    "        passing = result['passing_generations']\n",
    "        stats['total'] += 1\n",
    "        if passing == 0:\n",
    "            stats['passing_0'] += 1\n",
    "        elif passing == 1:\n",
    "            stats['passing_1'] += 1\n",
    "        elif passing == 2:\n",
    "            stats['passing_2'] += 1\n",
    "        elif passing == 3:\n",
    "            stats['passing_3'] += 1\n",
    "        elif passing == 4:\n",
    "            stats['passing_4'] += 1\n",
    "        elif passing == 5:\n",
    "            stats['passing_5'] += 1\n",
    "        \n",
    "        print(f\"  Result: {passing}/{NUM_GENERATIONS} generations passed\")\n",
    "        \n",
    "        # Print progress every 10 problems\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(\"\\n\" + \"-\" * 80)\n",
    "            print(f\"Progress: {idx + 1}/5018\")\n",
    "            print(f\"Stats: 0 passing: {stats['passing_0']}, 1: {stats['passing_1']}, \"\n",
    "                  f\"2: {stats['passing_2']}, 3: {stats['passing_3']}, \"\n",
    "                  f\"4: {stats['passing_4']}, 5: {stats['passing_5']}\")\n",
    "            print(\"-\" * 80)\n",
    "    \n",
    "    # Save results\n",
    "    print(f\"\\nSaving results to {OUTPUT_FILE}...\")\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    # Final summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PROCESSING COMPLETE\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total problems processed: {stats['total']}\")\n",
    "    print(f\"Problems with 0 passing: {stats['passing_0']}\")\n",
    "    print(f\"Problems with 1 passing: {stats['passing_1']}\")\n",
    "    print(f\"Problems with 2 passing: {stats['passing_2']}\")\n",
    "    print(f\"Problems with 3 passing: {stats['passing_3']}\")\n",
    "    print(f\"Problems with 4 passing: {stats['passing_4']}\")\n",
    "    print(f\"Problems with 5 passing: {stats['passing_5']}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd31423",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
